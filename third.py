# -*- coding: utf-8 -*-
"""THIRD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TFmLi3rL3XyQ9oWnk259ZWfuq9RpZLYT
"""

#NOW IN THIS THIRD STEP WE TAKE 1 IMAGE OF THE PERSON WHOM WE WANT TO RECOGNIZE
#USING THE SAME METHODS OF FIRST STEP COLOR IMAGE TO GRAY THEN SCALE AND THEN FLATTEN AND STORE IN PICKLE FILE
#IN THE SECOND BLOCK WE APPLY THE SAME CONCEPT OF PCA TO THE SINGLE RECOGNITION IMAGE
#STORE THE PRINCIPAL COMPONENTS TO IN PICKLE FILE


import cv2
import numpy as np
from matplotlib import pyplot as plt
import sys
import os
import time
import glob

from PIL import Image

#cap = cv2.VideoCapture(0)
#face_id = input("Enter a id")

user_name =input("Enter your Name")
print("Please capture 1 image with different movements")
count = 1
cap = cv2.VideoCapture(0)
while(True):

    ret, frame = cap.read()
    frame = cv2.flip(frame, 1, 0)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    #print(gray.shape)
    rec = cv2.rectangle(gray, (200,150), (400,350), (255,0,0), 2)
    crop_face = gray[150:350,200:400]
    #time.sleep(1)
    #print(crop_face.shape)
    cv2.imwrite("database1/"+user_name+str(count)+".png",crop_face)

    cv2.imshow('frame',gray)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
count +=1
cv2.destroyAllWindows()

    

numpy_image = []
files = glob.glob ("database1/*.png")
#print(files)
for myFile in files:
    #print(myFile)
    
    image = cv2.imread (myFile,0)
#     image = np.array(myFile)
    numpy_image.append(image)

print('Numpy_image shape:', np.array(numpy_image).shape)
# numpy_ima




numpy_image = np.asarray(numpy_image)
#print(numpy_image.shape)
scaled_images = []
for img in numpy_image:
    
    scale_percent = 30 # percent of original size
    width = int(img.shape[1] * scale_percent / 100)
    height = int(img.shape[0] * scale_percent / 100)
    dim = (width, height)
    # resize image
    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)
    scaled_images.append(resized)
# print/(scaled_images)    
plt.imshow(scaled_images[0])
plt.show()



flatten_image_array =[]
numpy_image = np.array(scaled_images)
#X_data.reshape(-1)
for image in numpy_image:
    flatten_image_array.append(image.reshape(-1))

    
flatten_image_array = np.array(flatten_image_array)
flatten_image_array

import pickle
numpy_image = np.asarray(flatten_image_array)
example = numpy_image
# pickle_out = open("dict3.pickle","wb")
# pickle.dump(example,pickle_out)
# pickle_out.close()

# import pickle
# pickle_in = open("dict3.pickle" , "rb") 
# example_dict1 = pickle.load(pickle_in)

import pickle
pickle_in = open("dict2.pickle" , "rb")
p = pickle.load(pickle_in)
print(p.shape)


from sklearn import preprocessing
from numpy.linalg import eigh
import numpy as np

data = np.reshape(example , (example.shape[0] ,3600))
data = preprocessing.normalize(data)
print(data.shape)
x_cap = data @ p.T
x_cap.shape

import pickle
numpy_image = np.asarray(x_cap)
example = numpy_image
pickle_out = open("dict4.pickle","wb")
pickle.dump(example,pickle_out)
pickle_out.close()

